# Legal Frontend (Virtual Receptionist) - Web

This folder contains a minimal React + Vite + Tailwind implementation of the "Virtual Receptionist" UI described in the project.

Key files:
- `src/VirtualReceptionist.tsx` - main page
- `src/components/AssistantAvatar.tsx` - avatar with Framer Motion
- `src/components/QueryBox.tsx` - text input + mic button
- `src/components/ResponseCard.tsx` - shows answer + references
- `src/api.ts` - Axios-based mock API wrapper
	- Endpoints used: `/api/stt`, `/api/query`, `/api/tts`, and optional `/api/gestures` for PantoMatrix video

Install and run (from this folder):

1. npm install
2. npm run dev

Notes:
- This is a UI scaffold. Install the dependencies listed in `package.json` (`react`, `vite`, `tailwindcss`, `framer-motion`, `axios`) to run.
- Backend endpoints expected: `/api/stt`, `/api/query`, `/api/tts`. Optionally, provide `/api/gestures` which accepts an audio file and returns a rendered gesture video (mp4) generated by PantoMatrix (EMAGE/CaMN/DisCo). The app uses `/api` base path so configure a proxy or run behind the backend.

## PantoMatrix integration (human-like gestures)

The UI has a toggle "Hiển thị cử chỉ giống con người (PantoMatrix)". When on, after TTS is generated the app sends the TTS audio to `/api/gestures` and shows the returned video.

Expected `/api/gestures` contract:
- Method: POST multipart/form-data
- Field: `file` (audio, wav/webm/mp3), single
- Response: either
  - `video/mp4` binary (recommended), OR
  - JSON `{ "videoUrl": "http://.../file.mp4" }`

Example FastAPI wrapper around PantoMatrix (outline only):

```python
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse
import uvicorn, os, tempfile, shutil, subprocess

app = FastAPI()

@app.post("/api/gestures")
async def gestures(file: UploadFile = File(...)):
	with tempfile.TemporaryDirectory() as tmp:
		in_wav = os.path.join(tmp, "in.wav")
		out_dir = os.path.join(tmp, "motion")
		os.makedirs(out_dir, exist_ok=True)
		with open(in_wav, 'wb') as f:
			shutil.copyfileobj(file.file, f)
		# Call PantoMatrix test script (EMAGE full body + face)
		# Assumes PantoMatrix and env are set up; replace paths accordingly
		subprocess.check_call([
			"python", "test_emage_audio.py",
			"--audio_folder", os.path.dirname(in_wav),
			"--save_folder", out_dir,
			"--visualization", "--nopytorch3d"
		], cwd="/path/to/PantoMatrix")
		# Resolve output mp4 (convention: <name>_2dface_audio.mp4 or similar)
		# For simplicity, pick first mp4 in out_dir
		mp4 = next((os.path.join(out_dir, f) for f in os.listdir(out_dir) if f.endswith('.mp4')), None)
		if not mp4:
			return {"error": "no video generated"}
		return FileResponse(mp4, media_type="video/mp4")

if __name__ == "__main__":
	uvicorn.run(app, host="0.0.0.0", port=8081)
```

Wire your backend `/api/gestures` to this service, or proxy `/api/gestures` to `http://localhost:8081/api/gestures` during development.

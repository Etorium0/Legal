# ğŸ­ PantoMatrix Avatar Integration Guide

## Tá»•ng quan

Frontend Ä‘Ã£ Ä‘Æ°á»£c chuáº©n bá»‹ sáºµn Ä‘á»ƒ tÃ­ch há»£p **PantoMatrix** - há»‡ thá»‘ng táº¡o avatar áº£o vá»›i gestures Ä‘á»“ng bá»™ theo lá»i nÃ³i. Hiá»‡n táº¡i Ä‘ang dÃ¹ng **mock/placeholder**, cáº§n tÃ­ch há»£p backend thá»±c.

## ğŸ¯ Workflow hiá»‡n táº¡i

```
User há»i cÃ¢u há»i
    â†“
Backend tráº£ lá»i (text)
    â†“
Frontend gá»i TTS API (text â†’ audio)
    â†“
Frontend gá»i Gestures API (audio â†’ video)
    â†“
Hiá»ƒn thá»‹ avatar video vá»›i gestures
```

## ğŸ“¦ CÃ¡c component Ä‘Ã£ cÃ³ sáºµn

### 1. **AssistantPage.tsx**
- âœ… Avatar video player vá»›i toggle báº­t/táº¯t
- âœ… State management cho avatar
- âœ… Audio playback
- âœ… Loading states
- âœ… Error handling

### 2. **api.ts**
- âœ… `ttsEndpoint()` - Mock TTS (táº¡o silent audio)
- âœ… `gesturesEndpoint()` - Mock gestures (táº¡o static image)
- âœ… Sáºµn sÃ ng Ä‘á»ƒ thay báº±ng real API calls

## ğŸ”§ CÃ¡ch tÃ­ch há»£p Backend thá»±c

### Backend cáº§n implement 2 endpoints:

#### 1. **TTS Endpoint** - Text to Speech
```bash
POST http://localhost:8080/api/v1/tts
Content-Type: application/json

Body:
{
  "text": "CÃ¢u nÃ³i cáº§n chuyá»ƒn thÃ nh giá»ng"
}

Response:
- Content-Type: audio/mpeg hoáº·c audio/wav
- Body: Binary audio data
```

**Gá»£i Ã½ implementation:**
- Google Cloud Text-to-Speech API
- Azure Cognitive Services Speech
- Amazon Polly
- FPT.AI Voice
- Viettel AI Voice

#### 2. **Gestures Endpoint** - PantoMatrix Video Generation
```bash
POST http://localhost:8080/api/v1/gestures
Content-Type: multipart/form-data

Body:
- file: audio file (WAV/MP3)

Response:
- Content-Type: video/mp4
- Body: Binary video data vá»›i avatar animation
```

**PantoMatrix Integration:**

1. **Clone PantoMatrix repo:**
```bash
git clone https://github.com/PantoMatrix/PantoMatrix
cd PantoMatrix
```

2. **Setup model:**
```bash
# Install dependencies
pip install -r requirements.txt

# Download pretrained models
# EMAGE, CaMN, DisCo models
```

3. **Táº¡o API wrapper (Python/FastAPI):**
```python
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse
import pantomatrix  # Your PantoMatrix wrapper

app = FastAPI()

@app.post("/generate-gestures")
async def generate_gestures(file: UploadFile = File(...)):
    # 1. Save uploaded audio
    audio_path = f"temp/{file.filename}"
    with open(audio_path, "wb") as f:
        f.write(await file.read())
    
    # 2. Run PantoMatrix model
    video_path = pantomatrix.generate(
        audio_path=audio_path,
        model="EMAGE",  # or CaMN, DisCo
        output_format="mp4"
    )
    
    # 3. Return video
    return FileResponse(
        video_path,
        media_type="video/mp4",
        filename="avatar.mp4"
    )
```

4. **Integrate vÃ o Go backend:**
```go
// internal/avatar/avatar.go
package avatar

import (
    "bytes"
    "io"
    "net/http"
)

const pantomatrixURL = "http://localhost:8000/generate-gestures"

func GenerateGestures(audioData []byte) ([]byte, error) {
    // Forward to PantoMatrix Python service
    resp, err := http.Post(
        pantomatrixURL,
        "audio/wav",
        bytes.NewReader(audioData),
    )
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    return io.ReadAll(resp.Body)
}

// cmd/api/main.go - Add route
r.Post("/api/v1/gestures", handleGestures)
```

## ğŸ”„ Update Frontend Ä‘á»ƒ dÃ¹ng real APIs

Khi backend Ä‘Ã£ sáºµn sÃ ng, update `src/api.ts`:

```typescript
export async function ttsEndpoint(text: string): Promise<{ url: string; blob: Blob }> 
{
  try 
  {
    // Call real backend TTS
    const res = await api.post('/tts', { text }, { 
      responseType: 'arraybuffer' 
    })
    
    const contentType = res.headers?.['content-type'] || 'audio/mpeg'
    const blob = new Blob([res.data], { type: contentType })
    const url = URL.createObjectURL(blob)
    return { url, blob }
  }
  catch (err: any) 
  {
    const msg = err?.response 
      ? `TTS error ${err.response.status}: ${JSON.stringify(err.response.data)}` 
      : err.message || String(err)
    throw new Error(msg)
  }
}

export async function gesturesEndpoint(audioBlob: Blob): Promise<{ url: string; type: string }>
{
  const form = new FormData()
  form.append('file', audioBlob, 'speech.wav')
  
  try 
  {
    // Call real backend PantoMatrix
    const res = await api.post('/gestures', form, {
      headers: { 'Content-Type': 'multipart/form-data' },
      responseType: 'arraybuffer'
    })
    
    const contentType = res.headers?.['content-type'] || 'video/mp4'
    const blob = new Blob([res.data], { type: contentType })
    const url = URL.createObjectURL(blob)
    return { url, type: contentType }
  }
  catch (err: any) 
  {
    const msg = err?.response 
      ? `Gestures error ${err.response.status}: ${JSON.stringify(err.response.data)}` 
      : err.message || String(err)
    throw new Error(msg)
  }
}
```

## ğŸ¨ UI Features Ä‘Ã£ cÃ³ sáºµn

### Avatar Player
- âœ… Responsive video/image player
- âœ… Aspect ratio 16:9
- âœ… Auto-play khi cÃ³ video má»›i
- âœ… Loading indicator
- âœ… Placeholder khi chÆ°a cÃ³ video

### Controls
- âœ… Toggle báº­t/táº¯t avatar
- âœ… Tá»± Ä‘á»™ng dá»«ng audio khi táº¯t
- âœ… Status indicators (Ä‘ang táº¡o, Ä‘Ã£ sáºµn sÃ ng)

### Integration vá»›i Chat
- âœ… Tá»± Ä‘á»™ng generate avatar khi cÃ³ response má»›i
- âœ… KhÃ´ng block UI (async)
- âœ… Graceful fallback náº¿u generation tháº¥t báº¡i

## ğŸ“Š Performance Considerations

### Caching
```typescript
// Cache generated videos Ä‘á»ƒ trÃ¡nh generate láº¡i
const videoCache = new Map<string, string>() // text â†’ videoUrl

export async function gesturesEndpointCached(
  audioBlob: Blob, 
  text: string
): Promise<{ url: string; type: string }> {
  // Check cache first
  if (videoCache.has(text)) {
    return { 
      url: videoCache.get(text)!, 
      type: 'video/mp4' 
    }
  }
  
  // Generate new
  const result = await gesturesEndpoint(audioBlob)
  videoCache.set(text, result.url)
  return result
}
```

### Optimization
- Preload avatar model khi app khá»Ÿi Ä‘á»™ng
- Stream video thay vÃ¬ Ä‘á»£i toÃ n bá»™
- Progressive loading
- Queue multiple requests

## ğŸ” Testing

### Test vá»›i mock data:
```bash
# Frontend Ä‘ang cháº¡y vá»›i mock
# Avatar sáº½ hiá»ƒn thá»‹ placeholder image
# Audio sáº½ silent
```

### Test vá»›i real backend:
```bash
# 1. Start PantoMatrix service
cd pantomatrix-service
uvicorn main:app --port 8000

# 2. Start Go backend
cd Legal-Supporter
docker-compose up -d

# 3. Test endpoint
curl -X POST http://localhost:8080/api/v1/tts \
  -H "Content-Type: application/json" \
  -d '{"text":"Xin chÃ o"}' \
  --output test.mp3

curl -X POST http://localhost:8080/api/v1/gestures \
  -F "file=@test.mp3" \
  --output test.mp4
```

## ğŸ“ Next Steps

1. **Setup PantoMatrix backend service**
   - Clone repo
   - Install models
   - Create API wrapper

2. **Implement Go backend endpoints**
   - `/api/v1/tts` - TTS service
   - `/api/v1/gestures` - PantoMatrix wrapper

3. **Update frontend api.ts**
   - Replace mock vá»›i real API calls
   - Add error handling
   - Add retry logic

4. **Optimize performance**
   - Implement caching
   - Add streaming
   - Preload models

5. **Testing**
   - Unit tests
   - Integration tests
   - Performance tests
   - User acceptance testing

## ğŸ¯ Status

- âœ… Frontend UI ready
- âœ… Mock APIs working
- â³ Backend TTS endpoint (cáº§n implement)
- â³ Backend Gestures endpoint (cáº§n implement)
- â³ PantoMatrix integration (cáº§n implement)

## ğŸ“š Resources

- [PantoMatrix GitHub](https://github.com/PantoMatrix/PantoMatrix)
- [EMAGE Paper](https://arxiv.org/abs/2304.11276)
- [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [FastAPI Docs](https://fastapi.tiangolo.com/)

---

**Káº¿t luáº­n:** Frontend Ä‘Ã£ sáºµn sÃ ng 100%, chá»‰ cáº§n backend implement 2 endpoints lÃ  cÃ³ thá»ƒ cháº¡y avatar vá»›i gestures thá»±c!
